{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import random\n",
    "import transformers\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import sys\n",
    "if '/home/ryparmar/experimental-martin/pretraining/src/' not in sys.path:\n",
    "    sys.path.append('/home/ryparmar/experimental-martin/pretraining/src')\n",
    "\n",
    "import util, io_util, eval\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from model import Encoder as Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.mode = 'finetuning'\n",
    "        self.task = 'BFS+ICT'\n",
    "        self.claims_path = \"/mnt/data/factcheck/CTK/dataset/v2.1/nfc\" #\"/mnt/data/factcheck/CTK/par5/ctk-data\"\n",
    "        self.articles_path = \"/mnt/data/factcheck/CTK/par5/interim/ctk_filtered.db\"\n",
    "        self.articles_chunks_path = \"/mnt/data/factcheck/ict_chunked_data/ids-chunks-288-finetuning-ctk_filtered.pkl\"\n",
    "\n",
    "#         self.claims_path = \"/mnt/data/factcheck/fever/data-cs/fever-data\"\n",
    "#         self.claims_path = \"/home/ryparmar/fever-cs-deepl\"\n",
    "#         self.articles_path = \"/mnt/data/factcheck/fever/data-cs/fever/fever.db\"\n",
    "#         self.articles_chunks_path = '/mnt/data/factcheck/ict_chunked_data/ids-chunks-288-finetuning-fever.pkl'\n",
    "        self.model_weight = \"/home/ryparmar/trained_models/debug.w\"\n",
    "        self.bert_model = \"bert-base-multilingual-cased\"\n",
    "        self.learning_rate = 5e-6\n",
    "        self.max_seq = 288\n",
    "        self.epoch = 1\n",
    "        self.bs = 32\n",
    "        self.test_bs = 64\n",
    "        self.remove_percent = 0.9\n",
    "        self.use_cuda = True if torch.cuda.is_available() else False\n",
    "        self.devices = \"0\" if torch.cuda.is_available() else \"\"\n",
    "        self.continue_training = \"/home/ryparmar/trained_models/mbert_pre_ctk_10ep_ict+bfs_1e-5_288\"\n",
    "#         \"/home/ryparmar/trained_models/mbert_wiki_pre_10ep-bfs_10ep-ict_1e-5_288\"  #False\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "    def add(self, name, val):\n",
    "        if name == 'cls_token_id':\n",
    "            self.cls_token_id = val\n",
    "        if name == 'pad_token_id':\n",
    "            self.pad_token_id = val\n",
    "        if name == 'device':\n",
    "            self.device = val\n",
    "        \n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_to(optim, device):\n",
    "    for param in optim.state.values():\n",
    "        # Not sure there are any global tensors in the state dict\n",
    "        if isinstance(param, torch.Tensor):\n",
    "            param.data = param.data.to(device)\n",
    "            if param._grad is not None:\n",
    "                param._grad.data = param._grad.data.to(device)\n",
    "        elif isinstance(param, dict):\n",
    "            for subparam in param.values():\n",
    "                if isinstance(subparam, torch.Tensor):\n",
    "                    subparam.data = subparam.data.to(device)\n",
    "                    if subparam._grad is not None:\n",
    "                        subparam._grad.data = subparam._grad.data.to(device)\n",
    "\n",
    "\n",
    "def instantiate_model(config, tokenizer):\n",
    "    configure_devices(config)\n",
    "    model = Model(config)\n",
    "    optimizer = transformers.AdamW(model.parameters(), lr=config.learning_rate, weight_decay=0)\n",
    "    metrics = None\n",
    "\n",
    "    if config.continue_training:\n",
    "        state_dict = torch.load(config.continue_training, map_location='cpu')\n",
    "        model.load_state_dict(state_dict['model'])\n",
    "        if 'optimizer_state_dict' in state_dict:\n",
    "            optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
    "        \n",
    "        try:\n",
    "            print(f\"Loaded model:\\nEpochs: {state_dict['epoch']}\\nLoss: {state_dict['loss']}\\n\", \n",
    "                  f\"Recall: {state_dict['rec']}\\nMRR: {state_dict['mrr']}\")\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    if config.use_cuda:\n",
    "        model = model.cuda()\n",
    "        optimizer_to(optimizer, config.device)\n",
    "        model = torch.nn.DataParallel(model, device_ids=config.devices)\n",
    "    return model, optimizer, metrics\n",
    "\n",
    "\n",
    "def configure_devices(config):\n",
    "    config.devices = [int(device) for device in range(torch.cuda.device_count())]\n",
    "    config.device = config.devices[0] if config.use_cuda else \"cpu\"\n",
    "\n",
    "\n",
    "def get_loader(data, batch_size):\n",
    "    data = TensorDataset(data)\n",
    "    return DataLoader(data,\n",
    "                      batch_size=batch_size,\n",
    "                      shuffle=True,\n",
    "                      sampler=None, drop_last=True)\n",
    "\n",
    "def ids2docs(ids, id2doc: dict):\n",
    "    return [id2doc[int(i)] for i in ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.BertTokenizerFast.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "\n",
    "config.add('cls_token_id', tokenizer.encode(tokenizer.cls_token, add_special_tokens=False)[0])\n",
    "config.add('pad_token_id', tokenizer.encode(tokenizer.pad_token, add_special_tokens=False)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model:\n",
      "Epochs: [0, 1, 2, 3]\n",
      "Loss: [0.6182721752268022, 0.4800995283004084, 0.4311975429328025, 0.4015651965180047]\n",
      " Recall: [0.517402, 0.433843, 0.493099, 0.392289]\n",
      "MRR: [0.29268, 0.217989, 0.262663, 0.177827]\n"
     ]
    }
   ],
   "source": [
    "model, optimizer, metrics = instantiate_model(config, tokenizer)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = eval.Metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tok(x):\n",
    "    print(tokenizer.convert_ids_to_tokens(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_chunks = util.make_chunks(config.articles_path, tokenizer, config, save_chunks=True)\n",
    "articles_ids = util.get_par_ids(doc_chunks) if 'CTK' in config.articles_path else list(doc_chunks.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "for k,v in doc_chunks.items():\n",
    "    s += len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13619573"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2507454"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_chunks['T201602040298002'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tok(doc_chunks['T201602040298002'][7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Padding chunks...: 100%|██████████| 2507454/2507454 [15:12<00:00, 2746.92it/s] \n"
     ]
    }
   ],
   "source": [
    "doc_chunks, chunks_mask = util.process_chunks(doc_chunks, config)\n",
    "dev_chunks, dev_chunks_mask, dev_articles_ids = doc_chunks, chunks_mask, articles_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_chunks['T201602040298002'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tok(doc_chunks['T201602040298002'][7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating evidences: 1it [00:00,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 300 claims from dev split.\n",
      "Loaded 2124 claims from train split.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating evidences: 1763it [03:22,  8.71it/s]\n",
      "Validating evidences: 218it [00:24,  8.77it/s]\n"
     ]
    }
   ],
   "source": [
    "claims_dev, evidence_dev, labels_dev = util.load_claims('dev', config)\n",
    "claims_train, evidence_train, labels_train = util.load_claims('train', config)\n",
    "claims_train, evidence_train, labels_train = util.remove_unverifiable_claims(claims_train,\n",
    "                                                                            evidence_train,\n",
    "                                                                            labels_train, config)\n",
    "claims_dev, evidence_dev, labels_dev = util.remove_unverifiable_claims(claims_dev,\n",
    "                                                                        evidence_dev,\n",
    "                                                                        labels_dev, config)\n",
    "\n",
    "claims_train, \\\n",
    "evidence_train, \\\n",
    "labels_train = util.remove_invalid_claims(claims_train, evidence_train, labels_train, articles_ids, config)\n",
    "\n",
    "claims_dev, \\\n",
    "evidence_dev, \\\n",
    "labels_dev = util.remove_invalid_claims(claims_dev, evidence_dev, labels_dev, articles_ids, config)\n",
    "\n",
    "claims_train, claims_train_mask = util.process_claims(claims_train, tokenizer, config, _pad_max=True)\n",
    "claims_dev, claims_dev_mask = util.process_claims(claims_dev, tokenizer, config, _pad_max=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_chunks['Astronomie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1712, 288])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claims_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2doc = {i: doc_id for i, (doc_id, _) in enumerate(doc_chunks.items())} if isinstance(doc_chunks, dict) else []\n",
    "    \n",
    "loader = (get_loader(torch.tensor([i for i in range(len(claims_train))]), config.bs) if config.mode == 'finetuning'\n",
    "          else get_loader(torch.tensor([i for i in range(len(doc_chunks))]), config.bs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_keys(keys: list, sample=0.01):\n",
    "        keys = list(dev_chunks.keys())\n",
    "        return random.sample(keys, round(len(keys)*sample))\n",
    "\n",
    "def get_subset(d: dict, keys: list):\n",
    "    return {k: d[k] for k in keys}\n",
    "    \n",
    "sample_keys = get_sample_keys(list(dev_chunks.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating chunks embeddings...: 100%|██████████| 25075/25075 [00:00<00:00, 50592.66it/s]\n",
      "Embedding given chunks...: 100%|██████████| 2125/2125 [11:33<00:00,  3.06it/s]\n",
      "Embedding given chunks...: 100%|██████████| 4/4 [00:01<00:00,  3.74it/s]\n"
     ]
    }
   ],
   "source": [
    "eval_claim_embed, eval_doc_embed = eval.evaluation_preprocessing(claims_dev, claims_dev_mask, \n",
    "                                                                    get_subset(dev_chunks, sample_keys), \n",
    "                                                                    get_subset(dev_chunks_mask, sample_keys), \n",
    "                                                                    model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_claim_embed, eval_doc_embed = eval.evaluation_preprocessing(claims_dev, claims_dev_mask, \n",
    "#                                                                     dev_chunks_s, dev_chunks_mask_s, model, config)\n",
    "# # del doc_chunks, chunks_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_claim_embed, eval_doc_embed = np.load('eval_claim_embed_deepl.npy'), np.load('eval_doc_embed_deepl.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('claim_embeddings_ctk', claim_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating evaluation metrics: 208it [05:15,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.0\tPrecision@20: 0.0\tRecall@20: 0.0\tMRR@20: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "precision, recall, f1, mrr = eval.retriever_score(eval_doc_embed, dev_articles_ids, eval_claim_embed, \n",
    "                                                evidence_dev, labels_dev, config, k=20)\n",
    "print(f\"F1: {f1}\\tPrecision@{20}: {precision}\\tRecall@{20}: {recall}\\tMRR@{20}: {mrr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ( get_loader(torch.tensor([i for i in range(len(claims_train))]), config.bs) \n",
    "               if config.mode == 'finetuning'\n",
    "               else get_loader(torch.tensor([i for i in range(len(doc_chunks))]), config.bs))\n",
    "\n",
    "id2doc = {i: doc_id for i, (doc_id, _) in enumerate(doc_chunks.items())} if isinstance(doc_chunks, dict) else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rand_chunk_id(chunks: list, ):\n",
    "    \"\"\"Returns a random chunk id from a list of chunks.\"\"\"\n",
    "    if len(chunks) > 0:\n",
    "        rand_chunk_id = random.sample(range(len(chunks)), 1)\n",
    "        return rand_chunk_id[0]\n",
    "    else:\n",
    "        print(\"ERROR -- EMPTY CHUNKS ON INPUT!\")\n",
    "\n",
    "def split_par_id(doc_id):\n",
    "    tmp = doc_id.split('_')\n",
    "    assert len(tmp) == 2\n",
    "    return tmp[0], tmp[1] \n",
    "    \n",
    "def bfs_finetuning_contexts(doc_chunks, doc_chunks_mask, evidence, is_ctk):\n",
    "    docs_pad, docs_mask = [], []\n",
    "    for ev_id in evidence:\n",
    "        if is_ctk:\n",
    "            doc_id, chunk_id = split_par_id(ev_id) \n",
    "        else:\n",
    "            ev_id, 0\n",
    "        print(doc_id, chunk_id)\n",
    "        rand_chunk_id = get_rand_chunk_id(list(doc_chunks[doc_id].keys()))\n",
    "        docs_pad.append(doc_chunks[doc_id][rand_chunk_id])\n",
    "        docs_mask.append(doc_chunks_mask[doc_id][rand_chunk_id])\n",
    "    return docs_pad, docs_mask\n",
    "\n",
    "\n",
    "def ict_finetuning_contexts(doc_chunks, doc_chunks_mask, evidence, is_ctk):\n",
    "    docs_pad, docs_mask = [], []\n",
    "    for ev_id in evidence:\n",
    "        if is_ctk:\n",
    "            doc_id, chunk_id = split_par_id(ev_id) \n",
    "        else:\n",
    "            ev_id, 0\n",
    "        print(doc_id, chunk_id)\n",
    "        docs_pad.append(doc_chunks[doc_id][int(chunk_id)])\n",
    "        docs_mask.append(doc_chunks_mask[doc_id][int(chunk_id)])\n",
    "    return docs_pad, docs_mask\n",
    "\n",
    "def get_finetuning_batch(batch_ids, claims, claims_mask, evidence, doc_chunks, doc_chunks_mask, doc_ids, config):\n",
    "    \"\"\"\n",
    "        Note: some negatives could be positives, as some claims have multiple supporting documents,\n",
    "        but that's being ignored here for convenience.\n",
    "    \"\"\"\n",
    "    claims_pad = [claims[i] for i in batch_ids]\n",
    "    claims_mask = [claims_mask[i] for i in batch_ids]\n",
    "    evidence = [evidence[i] for i in batch_ids]  # document ids\n",
    "    # doc_batch_ids = [doc_ids[i] for i in batch_ids]\n",
    "\n",
    "    # get documents\n",
    "    # 1 evidence = 1 doc id, see remove_unverifiable_claims\n",
    "    is_ctk = 'CTK' in config.articles_path\n",
    "    if config.task.upper() == 'BFS':  # works only for CTK data\n",
    "        docs_pad, docs_mask = bfs_finetuning_contexts(doc_chunks, doc_chunks_mask, evidence, is_ctk)\n",
    "    elif config.task.upper() == 'ICT':\n",
    "        docs_pad, docs_mask = ict_finetuning_contexts(doc_chunks, doc_chunks_mask, evidence, is_ctk)\n",
    "    else:\n",
    "        bfs = random.randint(0, 1)  # randomly choose between bfs / ict\n",
    "        docs_pad, docs_mask = (bfs_finetuning_contexts(doc_chunks, doc_chunks_mask, evidence, is_ctk)\n",
    "                               if bfs else \n",
    "                               ict_finetuning_contexts(doc_chunks, doc_chunks_mask, evidence, is_ctk))\n",
    "\n",
    "    c_p = torch.stack(claims_pad, axis=0).to(torch.int64).to(config.device)\n",
    "    c_m = torch.stack(claims_mask, axis=0).to(torch.int64).to(config.device)\n",
    "    d_p = torch.stack(docs_pad, axis=0).to(torch.int64).to(config.device)\n",
    "    d_m = torch.stack(docs_mask, axis=0).to(torch.int64).to(config.device)\n",
    "    return c_p, c_m, d_p, d_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T200609190631901 2\n",
      "20020512E01126 6\n",
      "T201306190678401 3\n",
      "20021121E03327 5\n",
      "T201602020591003 1\n",
      "20020510E05757 2\n",
      "T200705160360901 2\n",
      "20041130E05667 12\n",
      "T201802060970201 7\n",
      "20001120F02543 1\n",
      "20051013F01195 6\n",
      "T201308200032101 1\n",
      "T200609190631901 1\n",
      "20010601E01470 4\n",
      "T200603070946601 2\n",
      "T201608170388501 5\n",
      "T201008200353401 1\n",
      "20041215F00629 1\n",
      "T201602170965801 4\n",
      "20051004F01647 0\n",
      "T201512260018201 8\n",
      "T201512260018201 7\n",
      "20021118E02122 1\n",
      "20050128F00337 5\n",
      "T200708090259701 4\n",
      "T200801070228401 1\n",
      "T201208100100702 8\n",
      "T200603070946601 2\n",
      "T200710230390401 6\n",
      "20051107F00813 1\n",
      "T200805090117001 5\n",
      "T200710220515903 15\n",
      "torch.Size([32, 288]) torch.Size([32, 288])\n",
      "tensor([[   101,  23104,  10921,  ...,      0,      0,      0],\n",
      "        [   101,    139,  85430,  ...,      0,      0,      0],\n",
      "        [   101,    148,  16852,  ...,      0,      0,      0],\n",
      "        ...,\n",
      "        [   101,    152,  70673,  ...,      0,      0,      0],\n",
      "        [   101,  35248, 104693,  ...,      0,      0,      0],\n",
      "        [   101,  46361,  48832,  ...,      0,      0,      0]],\n",
      "       device='cuda:0') tensor([[  101, 17410, 10270,  ...,     0,     0,     0],\n",
      "        [  101, 49869, 72806,  ...,     0,     0,     0],\n",
      "        [  101,   148, 16852,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  101,   100,   100,  ...,     0,     0,     0],\n",
      "        [  101, 10159, 23236,  ...,     0,     0,     0],\n",
      "        [  101, 15807, 29184,  ...,     0,     0,     0]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(loader))\n",
    "batch = batch[0]\n",
    "query, query_mask, \\\n",
    "context, context_mask = get_finetuning_batch(batch, claims_train, claims_train_mask, evidence_train,\n",
    "                                                pad_doc_chunks, chunks_mask, articles_ids, config)\n",
    "print(f\"{query.shape} {context.shape}\")\n",
    "print(f\"{query} {context}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/28 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T201503290538903 1\n",
      "T201306190678401 3\n",
      "20051013F01195 6\n",
      "20050128F00337 5\n",
      "T201602040298002 7\n",
      "20030130E01450 1\n",
      "20020618F00388 1\n",
      "20030307E00262 2\n",
      "20030427E00825 4\n",
      "T200805090117001 5\n",
      "20010220F01423 4\n",
      "20030612F02104 1\n",
      "20051107F00813 1\n",
      "T201609260734602 1\n",
      "T200709190711502 7\n",
      "T201210160213901 1\n",
      "20050711F01819 5\n",
      "20050601F01415 3\n",
      "T201306130258101 1\n",
      "T201003150613402 3\n",
      "20011220E01142 4\n",
      "T200803070230601 3\n",
      "T200609190631901 1\n",
      "T201406160291201 6\n",
      "20030612F02104 2\n",
      "20030427E00825 4\n",
      "T201512260018201 1\n",
      "T200805190455401 3\n",
      "20010711F01495 1\n",
      "T200705160360901 1\n",
      "20060118F01474 2\n",
      "T201306190678401 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 1/28 [03:38<1:38:27, 218.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch_avg_loss: 0.9218634366989136\n",
      "running_loss: 29.499629974365234\n",
      "T201510070563901 2\n",
      "T200805190455401 1\n",
      "T201710180270101 2\n",
      "T200709190711502 9\n",
      "T201210160213901 4\n",
      "20040213E02401 5\n",
      "20021121E03327 5\n",
      "T201604210827502 1\n",
      "20001120F02543 1\n",
      "20020624F03306 2\n",
      "T200603070906101 3\n",
      "T201510070563901 2\n",
      "20010311E01129 3\n",
      "T201509140642301 4\n",
      "T200609190631901 2\n",
      "20040111E00954 1\n",
      "T201004280441801 3\n",
      "20040111E00954 1\n",
      "T200710230390401 2\n",
      "20000612F00401 5\n",
      "20030611F01030 4\n",
      "T201611231017401 4\n",
      "20030427E00825 2\n",
      "T200603070946601 5\n",
      "T200603070946601 2\n",
      "20020723F01050 7\n",
      "20010101E00080 6\n",
      "T201511090723301 1\n",
      "20060113E00817 3\n",
      "20020422F01825 1\n",
      "20010510F01902 1\n",
      "T201004210977301 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 1/28 [07:19<3:17:54, 439.80s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-6d3ad43f9210>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mcorrect_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/appl/software/PyTorch/1.5.1-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/appl/software/PyTorch/1.5.1-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch_num = -1\n",
    "for epoch_num in range(config.epoch):\n",
    "    model.train()\n",
    "    batch_num = len(loader)\n",
    "    num_training_examples, running_loss = 0, 0.0\n",
    "    for batch in tqdm(loader, total=batch_num):\n",
    "        optimizer.zero_grad()\n",
    "        batch = batch[0]\n",
    "        num_training_examples += batch.size(0)\n",
    "        if config.mode == 'finetuning':\n",
    "            query, query_mask, \\\n",
    "            context, context_mask = get_finetuning_batch(batch, claims_train, claims_train_mask, evidence_train,\n",
    "                                                            doc_chunks, chunks_mask, articles_ids, config)\n",
    "        else:\n",
    "            query, query_mask, \\\n",
    "            context, context_mask = util.get_pretraining_batch(ids2docs(batch, id2doc), doc_chunks, \n",
    "                                                                        tokenizer, config)\n",
    "\n",
    "        query_cls_out = model(x=query, x_mask=query_mask)\n",
    "        context_cls_out = model(x=context, x_mask=context_mask)\n",
    "        logit = torch.matmul(query_cls_out, context_cls_out.transpose(-2, -1))\n",
    "        correct_class = torch.tensor([i for i in range(len(query))]).long().to(config.device)\n",
    "        loss = loss_fn(logit, correct_class)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * batch.size(0)\n",
    "        epoch_avg_loss = running_loss / num_training_examples\n",
    "\n",
    "        print(f\"epoch_avg_loss: {epoch_avg_loss}\\nrunning_loss: {running_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(claims_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T201608150566901'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dev_chunks.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dev_chunks['T201608150566901'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating chunks embeddings...: 100%|██████████| 2507454/2507454 [00:39<00:00, 62906.39it/s]\n"
     ]
    }
   ],
   "source": [
    "embeddings, doc_ids, par_ids = [], [], []\n",
    "chunks, masks = dev_chunks, chunks_mask\n",
    "if isinstance(dev_chunks, dict) and isinstance(chunks_mask, dict):\n",
    "    chunks, masks = [], []\n",
    "    for doc_id, doc in tqdm(dev_chunks.items(), desc='Generating chunks embeddings...'):\n",
    "        doc_ids.append(doc_id)\n",
    "        if isinstance(doc, list):\n",
    "            chunks.append(util.flatten_list(doc))\n",
    "            masks.append(util.flatten_list(chunks_mask[doc_id]))\n",
    "        elif isinstance(doc, dict):\n",
    "            for par_id, par in doc.items():\n",
    "                par_ids.append(par_id)\n",
    "                if isinstance(par, list):\n",
    "                    chunks.append(util.flatten_list(par))\n",
    "                    masks.append(util.flatten_list(chunks_mask[doc_id][par_id]))\n",
    "                else:\n",
    "                    chunks.append(torch.flatten(par))\n",
    "                    masks.append(torch.flatten(chunks_mask[doc_id][par_id]))\n",
    "        else:\n",
    "            chunks.append(torch.flatten(doc))\n",
    "            masks.append(torch.flatten(chunks_mask[doc_id]))\n",
    "elif isinstance(dev_chunks, list) and isinstance(masks, list):\n",
    "    chunks = torch.stack(chunks, axis=0)\n",
    "    masks = torch.stack(masks, axis=0)\n",
    "\n",
    "# embeddings = encode_chunks(chunks, masks, model, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = torch.stack(chunks, axis=0)\n",
    "masks = torch.stack(masks, axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chunks)#[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13619573, 288])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding given chunks...: 100%|██████████| 3/3 [02:27<00:00, 49.20s/it]\n"
     ]
    }
   ],
   "source": [
    "claim_embeddings = eval.encode(claims_dev, claims_dev_mask, model, batch_size=config.test_bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding given chunks...:   0%|          | 2/425612 [01:14<4418:45:07, 37.38s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-99fc12d2e88f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdocument_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/experimental-martin/pretraining/src/eval.py\u001b[0m in \u001b[0;36mencode_chunks\u001b[0;34m(chunks, chunks_mask, model, batch_size)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Embedding given chunks...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             cls_output = model(x=chunks[i:i + batch_size],\n\u001b[0;32m--> 240\u001b[0;31m                             x_mask=chunks_mask[i:i + batch_size])\n\u001b[0m\u001b[1;32m    241\u001b[0m             \u001b[0mchunks_encode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks_encode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/appl/software/PyTorch/1.5.1-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/experimental-martin/pretraining/src/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, x_mask)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;31m# print(output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# out.last_hidden_state.shape = torch.Size([4, 85, 768]), where (batch_size, max_seq_length, token embedding size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/appl/software/PyTorch/1.5.1-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m         )\n\u001b[1;32m    874\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/appl/software/PyTorch/1.5.1-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    505\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m                 )\n\u001b[1;32m    509\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/appl/software/PyTorch/1.5.1-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         )\n\u001b[1;32m    428\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/appl/software/PyTorch/1.5.1-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         )\n\u001b[1;32m    365\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/appl/software/PyTorch/1.5.1-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mattention_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_probs\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m         \u001b[0mcontext_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0mcontext_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "document_embeddings = eval.encode_chunks(chunks, masks, model, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101, 85566, 91931, 20819,   190, 10730, 33302, 33705, 14590, 10419,\n",
       "        10132, 79420, 81592, 10147,   280, 89424, 10126, 21484, 10545, 20639,\n",
       "        11163, 38320,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.flatten(dev_chunks['T201608150566901'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating chunks embeddings...:   0%|          | 0/2507454 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "flatten(): argument 'input' (position 1) must be Tensor, not dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-0a255264a286>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m eval_claim_embed, eval_doc_embed = eval.evaluation_preprocessing(claims_dev, claims_dev_mask, \n\u001b[0;32m----> 3\u001b[0;31m                                                                 dev_chunks, dev_chunks_mask, model, config)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m precision, recall, f1, mrr = eval.retriever_score(eval_doc_embed, dev_articles_ids, eval_claim_embed, \n",
      "\u001b[0;32m~/experimental-martin/pretraining/src/eval.py\u001b[0m in \u001b[0;36mevaluation_preprocessing\u001b[0;34m(claims_tokenized, claim_masks, context_chunks, context_chunk_masks, model, config)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluation_preprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclaims_tokenized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclaim_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_chunk_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m     \u001b[0mdocument_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_chunk_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_bs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Documents embedded with shape: {document_embeddings.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0mclaim_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclaims_tokenized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclaim_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_bs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/experimental-martin/pretraining/src/eval.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(doc_chunks, chunks_mask, model, batch_size)\u001b[0m\n\u001b[1;32m    261\u001b[0m                         \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpar_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m                         \u001b[0mchunks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m                         \u001b[0mmasks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: flatten(): argument 'input' (position 1) must be Tensor, not dict"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "eval_claim_embed, eval_doc_embed = eval.evaluation_preprocessing(claims_dev, claims_dev_mask, \n",
    "                                                                dev_chunks, dev_chunks_mask, model, config)\n",
    "\n",
    "precision, recall, f1, mrr = eval.retriever_score(eval_doc_embed, dev_articles_ids, eval_claim_embed, \n",
    "                                                evidence_dev, labels_dev, config, k=20)\n",
    "print(f\"F1: {f1}\\tPrecision@{20}: {precision}\\tRecall@{20}: {recall}\\tMRR@{20}: {mrr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(sdev_ch), type(sdev_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_claim_embeddings, eval_document_embeddings = eval.evaluation_preprocessing(claims_dev, claims_dev_mask, \n",
    "#                                                                                 sdev_ch, sdev_m, model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(eval_claim_embeddings.shape, eval_document_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kk = 20\n",
    "# precision, recall, f1, mrr = eval.retriever_score(eval_document_embeddings,dev_articles_ids, eval_claim_embeddings, \n",
    "#                                             evidence_dev, labels_dev, config, k=kk)\n",
    "# print(f\"F1: {f1}\\tPrecision@{kk}: {precision}\\tRecall@{kk}: {recall}\\tMRR@{kk}: {mrr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paragraph len distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"/mnt/data/factcheck/fever/data-cs/fever/fever.db\"\n",
    "path = \"/mnt/data/factcheck/CTK/par5/interim/ctk_filtered.db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process abstract wiki\n",
    "pars, par_ids = io_util.load_db(path)  # returns paragraphs and paragraph ids\n",
    "docs = util.transform_fever_wiki(pars, par_ids)  # group paragraphs of articles\n",
    "docs_tokenized = util.tokenize_documents(docs, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process full len wiki\n",
    "wiki_json = io_util.load_json(path)\n",
    "docs = transform_wiki(wiki_json)\n",
    "docs_tokenized = tokenize_documents(docs, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process ctk\n",
    "pars, par_ids = io_util.load_db(path)  # returns paragraphs and paragraph ids\n",
    "pars, par_ids = util.remove_invalid_pars(pars, par_ids)\n",
    "docs = util.transform_ctk(pars, par_ids)  # group paragraphs for each article\n",
    "# generate at once\n",
    "docs_tokenized = util.tokenize_documents(docs, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc_id, doc in docs_tokenized.items():\n",
    "    for par_id, par in doc.items():\n",
    "#         print(par)\n",
    "        for sent in par:\n",
    "            print(len(sent), sent)\n",
    "        print(sum([len(sent) for sent in par]))\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = [sum([len(sent) for sent in par]) for doc_id, doc in docs_tokenized.items() for par_id, par in doc.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens_doc = [sum([len(sent) for sent in par for _,par in doc.items()]) for doc_id, doc in docs_tokenized.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lens_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.xlabel('# tokens', fontsize=12)\n",
    "plt.title(f'Distribution by a number of tokens (subwords) in paragraph\\nCTK')\n",
    "plt.hist(\n",
    "    lens, 25,\n",
    "    histtype='bar',\n",
    "    facecolor='black',\n",
    "    alpha=0.5,\n",
    "    range=(0, 600),)\n",
    "\n",
    "plt.savefig(\"ctk-par-len-dist-600.svg\", format=\"svg\")\n",
    "\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
