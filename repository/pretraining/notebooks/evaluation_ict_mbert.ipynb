{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla V100-SXM2-32GB\n",
      "Requirement already satisfied: transformers in /home/pitrmich/.local/lib/python3.7/site-packages (3.0.2)\n",
      "Requirement already satisfied: requests in /mnt/appl/software/Python/3.7.4-GCCcore-8.3.0/lib/python3.7/site-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92 in /home/pitrmich/.local/lib/python3.7/site-packages (from transformers) (0.1.91)\n",
      "Requirement already satisfied: sacremoses in /home/pitrmich/.local/lib/python3.7/site-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: numpy in /mnt/appl/software/SciPy-bundle/2019.10-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages (from transformers) (1.17.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/pitrmich/.local/lib/python3.7/site-packages (from transformers) (4.47.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/pitrmich/.local/lib/python3.7/site-packages (from transformers) (2020.7.14)\n",
      "Requirement already satisfied: filelock in /home/pitrmich/.local/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging in /mnt/appl/software/Python/3.7.4-GCCcore-8.3.0/lib/python3.7/site-packages (from transformers) (19.1)\n",
      "Requirement already satisfied: tokenizers==0.8.1.rc1 in /home/pitrmich/.local/lib/python3.7/site-packages (from transformers) (0.8.1rc1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/appl/software/Python/3.7.4-GCCcore-8.3.0/lib/python3.7/site-packages (from requests->transformers) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /mnt/appl/software/Python/3.7.4-GCCcore-8.3.0/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /mnt/appl/software/Python/3.7.4-GCCcore-8.3.0/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /mnt/appl/software/Python/3.7.4-GCCcore-8.3.0/lib/python3.7/site-packages (from requests->transformers) (1.25.3)\n",
      "Requirement already satisfied: click in /mnt/appl/software/Python/3.7.4-GCCcore-8.3.0/lib/python3.7/site-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: six in /mnt/appl/software/Python/3.7.4-GCCcore-8.3.0/lib/python3.7/site-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: joblib in /home/pitrmich/.local/lib/python3.7/site-packages (from sacremoses->transformers) (0.16.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /mnt/appl/software/Python/3.7.4-GCCcore-8.3.0/lib/python3.7/site-packages (from packaging->transformers) (2.4.2)\n",
      "Requirement already satisfied: attrs in /mnt/appl/software/Python/3.7.4-GCCcore-8.3.0/lib/python3.7/site-packages (from packaging->transformers) (19.1.0)\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 20.2.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: wget in /home/pitrmich/.local/lib/python3.7/site-packages (3.2)\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 20.2.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    model = Encoder(config)\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "!python -m pip install transformers\n",
    "!python -m pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fever.db\r\n"
     ]
    }
   ],
   "source": [
    "ls /mnt/data/factcheck/fever/data-cs/fever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# The URL for the dataset .db file.\n",
    "dataset_path = '/mnt/data/factcheck/fever/data-cs/fever/fever.db'\n",
    "devset_path = '/mnt/data/factcheck/fever/data-cs/fever-data/dev.jsonl'\n",
    "\n",
    "# Create the connection\n",
    "connection = sqlite3.connect(dataset_path)\n",
    "\n",
    "# create the dataframe from a query\n",
    "wiki = pd.read_sql_query(\"SELECT * FROM documents\", connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 107330 records from train.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def dump_jsonl(data, output_path, append=False):\n",
    "    \"\"\"\n",
    "    Write list of objects to a JSON lines file.\n",
    "    \"\"\"\n",
    "    mode = 'a+' if append else 'w'\n",
    "    with open(output_path, mode, encoding='utf-8') as f:\n",
    "        for line in data:\n",
    "            json_record = json.dumps(line, ensure_ascii=False)\n",
    "            f.write(json_record + '\\n')\n",
    "    print('Wrote {} records to {}'.format(len(data), output_path))\n",
    "\n",
    "def load_jsonl(input_path) -> list:\n",
    "    \"\"\"\n",
    "    Read list of objects from a JSON lines file.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line.rstrip('\\n|\\r')))\n",
    "    print('Loaded {} records from {}'.format(len(data), input_path))\n",
    "    return data \n",
    "\n",
    "webpage_data = load_jsonl('train.jsonl')\n",
    "db_data = []\n",
    "db_cols = ['id', 'verifiable', 'label', 'claim', 'evidence', 'claim_en']  # edit this to suit the jsonl file\n",
    "for d in webpage_data:\n",
    "    db_data.append([])\n",
    "    for col in db_cols:\n",
    "        db_data[-1].append(d.get(col, float('nan')))\n",
    "        \n",
    "devset = pd.DataFrame(db_data, columns=db_cols)\n",
    "\n",
    "claims = devset.claim.values\n",
    "evidence = devset.evidence.values \n",
    "labels = devset.label.values\n",
    "\n",
    "corpus_full = wiki.text.values\n",
    "corpus_full_id = wiki.id.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 451629/451629 [01:00<00:00, 7469.14it/s]\n"
     ]
    }
   ],
   "source": [
    "sent_split = [nltk.sent_tokenize(article) for article in tqdm(corpus_full)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "tokenizer = transformers.tokenization_bert.BertTokenizer.from_pretrained('bert-base-multilingual-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 451629/451629 [07:01<00:00, 1070.99it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Takes in a list of lists of sentences and returns a list of lists of tokenized sentences\"\"\"\n",
    "tokenized_articles = [[[tokenizer.vocab[word_piece]for word_piece in tokenizer.tokenize(sent)] for sent in article] for article in tqdm(sent_split)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_list_len(lst):\n",
    "    total_sum = 0\n",
    "    for sub_lst in lst:\n",
    "        total_sum += len(sub_lst)\n",
    "    return total_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this depending on your model\n",
    "max_seq_len = 288\n",
    "split_article_into_chunks = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "451629it [00:03, 140094.50it/s]\n"
     ]
    }
   ],
   "source": [
    "if split_article_into_chunks:\n",
    "    chunks = []\n",
    "    wiki_ids_experimental = []\n",
    "    for i, article in tqdm(enumerate(tokenized_articles)):\n",
    "        max_len = max_seq_len - 1 # has to be the same as the max sequence length your model was trained on\n",
    "        chunk = []\n",
    "        article_chunks = []\n",
    "        for sentence in article:\n",
    "            if nested_list_len(chunk) + len(sentence) > max_len:\n",
    "                # a complete chunk\n",
    "                article_chunks.append(chunk) # for counting (yeaah , wasteful) #TODO improve\n",
    "                chunks.append(chunk)\n",
    "                # add the current sentence to a new chunk\n",
    "                chunk = [sentence]\n",
    "            else:\n",
    "                chunk.append(sentence)\n",
    "        if chunk != []:\n",
    "            article_chunks.append(chunk) # for counting, #TODO improve\n",
    "            chunks.append(chunk)\n",
    "\n",
    "        # add all the chunks from an article to chunks         \n",
    "    #     chunks.append(article_chunks)\n",
    "        #create wiki_ids so that each chunk has an appropriate wiki_id\n",
    "        for j in range(len(article_chunks)):\n",
    "            wiki_ids_experimental.append(corpus_full_id[i])\n",
    "else:\n",
    "    chunks = []\n",
    "    for article in tokenized_articles:\n",
    "        max_len = max_seq_len - 1 # has to be the same as the max sequence length your model was trained on\n",
    "        chunk = []\n",
    "        for sentence in article:\n",
    "            if nested_list_len(chunk) + len(sentence) > max_len:\n",
    "                break\n",
    "            else:\n",
    "                chunk.append(sentence)\n",
    "        chunks.append(chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunks = []\n",
    "# for article in tokenized_articles:\n",
    "#     max_len = max_seq_len - 1 # has to be the same as the max sequence length your model was trained on\n",
    "#     chunk = []\n",
    "#     for sentence in article:\n",
    "#         if nested_list_len(chunk) + len(sentence) > max_len:\n",
    "#             break\n",
    "#         else:\n",
    "#             chunk.append(sentence)\n",
    "#     chunks.append(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chunks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_chunks = []\n",
    "for chunk in chunks:\n",
    "    flat_chunk = []\n",
    "    for sentence in chunk:\n",
    "        for token in sentence:\n",
    "            flat_chunk.append(token)\n",
    "    flat_chunks.append(flat_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510199\n",
      "451629\n"
     ]
    }
   ],
   "source": [
    "print(len(flat_chunks))\n",
    "print(len(corpus_full))\n",
    "#so there's a 60000 new chunks to search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "del chunks\n",
    "del tokenized_articles\n",
    "del sent_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#need to add tokens to chunks #for some reason the source code doesn't use \"[SEP]\" tokens\n",
    "vocab = dict()\n",
    "for k, v in tokenizer.vocab.items():\n",
    "    vocab[k] = v\n",
    "start_token = vocab[\"[CLS]\"]\n",
    "[chunk.insert(0, start_token) for chunk in flat_chunks]\n",
    "# flat_chunks[1]\n",
    "#need to pad to max seq length\n",
    "chunk, chunk_mask = util.pad_sequence(flat_chunks, max_seq=max_seq_len, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import transformers\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \"\"\" a wrapper class for Huggingface transformer models\"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder = transformers.modeling_bert.BertModel.from_pretrained(config['bert_model'])\n",
    "        self.linear = torch.nn.Linear(768, 512) # from Two-tower paper\n",
    "        self.config = config\n",
    "\n",
    "    def forward(self, x, x_mask):\n",
    "        hidden, x = self.encoder(input_ids=x, attention_mask=x_mask)\n",
    "        hidden = self.linear(hidden[:, 0]) # selects cls token\n",
    "        return hidden, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'bert_model':'bert-base-multilingual-cased', \n",
    "    'devices':device,\n",
    "    'do_lower':False,\n",
    "    'max_seq' :max_seq_len, \n",
    "    'model_weight':'./trained_models/mbert_ict_288_cls_20epoch_lr=1e-5_512layer.w', # path to your model\n",
    "    'use_cuda':True, \n",
    "}\n",
    "\n",
    "model = Encoder(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, device):\n",
    "    model_to_load = model.module if hasattr(model, 'module') else model\n",
    "    load_dict = torch.load(config[\"model_weight\"], map_location=lambda storage, loc: storage.cuda(device))\n",
    "    model_to_load.load_state_dict(load_dict['model'])\n",
    "    return model_to_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (encoder): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=768, out_features=512, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model(model, device) # uncommented as I am testing the baseline performance\n",
    "model.cuda()\n",
    "model.eval() #turn into evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15944/15944 [45:01<00:00,  5.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# chunk_mask.to(\"cuda\")\n",
    "# chunk.to(\"cuda\")\n",
    "chunk_encode = []\n",
    "batch_size = 32 # depends on your gpu vram. I haven't played around with this too much, but \n",
    "#ideally make it a power of 2 \n",
    "with torch.no_grad(): # don't want to accumulate gradients when doing inference\n",
    "    for i in tqdm(range(0, len(chunk), batch_size)):\n",
    "        c_hidden, c_encode = model(x=chunk[i:i+batch_size], x_mask=chunk_mask[i:i+batch_size]) #now using the cls token\n",
    "        chunk_encode.append(c_hidden.detach().cpu().numpy())\n",
    "document_embeddings = np.concatenate(chunk_encode, axis=0)\n",
    "del chunk_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus_full_id[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug_claims = [\"Vietnamská jídla odráží elementy\", \"Chrám Trandruk se nachází 5km od Cethangu\"]\n",
    "# evidence = [\"Vietnamská kuchyně\", \"Cethang\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_claims = [[tokenizer.vocab[word_piece] for word_piece in tokenizer.tokenize(claim)] for claim in claims]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "[claim.insert(0, start_token) for claim in tokenized_claims] #inserts only [CLS] token, \n",
    "# as that's what ICT was trained with\n",
    "#need to pad to max seq length\n",
    "claims_padded, claims_mask = util.pad_sequence(tokenized_claims, max_seq=max_seq_len, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3067/3067 [05:57<00:00,  8.59it/s]\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "# claims.to(\"cpu\")\n",
    "# claims_mask.to('cpu')\n",
    "claims_encode = []\n",
    "batch_size = 35\n",
    "\n",
    "with torch.no_grad(): # don't want to accumulate gradients when doing inference\n",
    "    for i in tqdm(range(0, len(claims), batch_size)):\n",
    "        claim_hidden, claim_encode = model(x=claims_padded[i:i+batch_size], x_mask=claims_mask[i:i+batch_size])\n",
    "        claims_encode.append(claim_hidden.detach().cpu().numpy()) #select the cls token\n",
    "\n",
    "claim_embeddings = np.concatenate(claims_encode, axis=0)\n",
    "del claims_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-gpu in /home/pitrmich/.local/lib/python3.7/site-packages (1.6.3)\n",
      "Requirement already satisfied: numpy in /mnt/appl/software/SciPy-bundle/2019.10-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages (from faiss-gpu) (1.17.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-gpu --no-cache --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "def search_top_k(corp_emb, query_emb, embedding_dim=512, k=10, metric=faiss.METRIC_INNER_PRODUCT):\n",
    "    '''\n",
    "    Returns a tuple with ordered lists of lists of cosine distances between and top k matches in corpus_embeddings. \n",
    "    Each list corresponds to one query.\n",
    "    Needs GPU\n",
    "    Available metrics = faiss.METRIC_INNER_PRODUCT, faiss.METRIC_L2, ...\n",
    "    more here https://github.com/facebookresearch/faiss/wiki/MetricType-and-distances\n",
    "    \n",
    "    return type = (List[List[cosine_distance]], List[List[index_of_corpus_embedding]]); \n",
    "    type(cosine_distance) == Float\n",
    "    type(index_of_corpus_embedding) == Int\n",
    "    '''\n",
    "\n",
    "    index = faiss.index_factory(embedding_dim, \"Flat\", metric) # Flat = exhaustive search\n",
    "    if metric == faiss.METRIC_INNER_PRODUCT:\n",
    "        faiss.normalize_L2(corp_emb) # need to normalize query and corpus vectors for cosine distance\n",
    "        faiss.normalize_L2(query_emb)\n",
    "        \n",
    "    res = faiss.StandardGpuResources()\n",
    "    gpu_index = faiss.index_cpu_to_gpu(res, 0, index) # use gpu\n",
    "    gpu_index.add(corp_emb)\n",
    "    return gpu_index.search(query_emb, k)\n",
    "\n",
    "def evidence_macro_precision(evidence, label, predicted_evid, max_evidence=None, page_only=True):\n",
    "    \"\"\"\n",
    "    precision = predicted\n",
    "    \"\"\"\n",
    "    this_precision = 0.0\n",
    "    this_precision_hits = 0.0\n",
    "\n",
    "    if label.upper() != \"NOT ENOUGH INFO\":\n",
    "        if page_only:\n",
    "            all_evi = [e[2] for eg in evidence for e in eg if e[3] is not None]\n",
    "            \n",
    "        else:\n",
    "            all_evi = [[e[2], e[3]] for eg in evidence for e in eg if e[3] is not None]\n",
    "        for prediction in predicted_evid:\n",
    "            if prediction in all_evi:\n",
    "                this_precision += 1.0\n",
    "            this_precision_hits += 1.0\n",
    "\n",
    "        return (this_precision / this_precision_hits) if this_precision_hits > 0 else 1.0, 1.0\n",
    "\n",
    "    return 0.0, 0.0\n",
    "\n",
    "def evidence_macro_recall(evidence, label ,predicted_evidence, max_evidence=None, page_only=True):\n",
    "    # We only want to score F1/Precision/Recall of recalled evidence for NEI claims\n",
    "    if label.upper() != \"NOT ENOUGH INFO\":\n",
    "        # If there's no evidence to predict, return 1\n",
    "        if len(evidence) == 0: #or all([len(eg) == 0 for eg in instance]):\n",
    "            return 1.0, 1.0\n",
    "\n",
    "        for evidence_group in evidence:\n",
    "            evidence = [e[2] for e in evidence_group] if page_only else [[e[2], e[3]] for e in evidence_group]\n",
    "            if all([item in predicted_evidence for item in evidence]):\n",
    "                # We only want to score complete groups of evidence. Incomplete groups are worthless.\n",
    "                return 1.0, 1.0\n",
    "            \n",
    "        return 0.0, 1.0\n",
    "    return 0.0, 0.0\n",
    "\n",
    "def retriever_score(corpus_embeddings, query_embeddings, evidence, labels, \\\n",
    "                                   corpus_ids, k=10, metric=faiss.METRIC_INNER_PRODUCT):\n",
    "    macro_precision = 0\n",
    "    macro_precision_hits = 0\n",
    "    \n",
    "    macro_recall = 0\n",
    "    macro_recall_hits = 0\n",
    "    \n",
    "    D, I = search_top_k(corpus_embeddings, np.asarray(query_embeddings), metric=faiss.METRIC_INNER_PRODUCT, k=k)\n",
    "    \n",
    "    for i, top_k_idxs in enumerate(I):\n",
    "        if i%100 == 0 and i != 0:\n",
    "            print(\"claim \", i)\n",
    "        predicted_evidence = np.take(corpus_ids, I[i])\n",
    "        \n",
    "        macro_prec = evidence_macro_precision(evidence[i], labels[i], predicted_evidence, max_evidence=None, page_only=True)\n",
    "        macro_precision += macro_prec[0]\n",
    "        macro_precision_hits += macro_prec[1]\n",
    "        \n",
    "        macro_rec = evidence_macro_recall(evidence[i], labels[i], predicted_evidence)\n",
    "        macro_recall += macro_rec[0]\n",
    "        macro_recall_hits += macro_rec[1]\n",
    "        \n",
    "    pr = (macro_precision / macro_precision_hits) if macro_precision_hits > 0 else 1.0\n",
    "    rec = (macro_recall / macro_recall_hits) if macro_recall_hits > 0 else 0.0\n",
    "    f1 = 2.0 * pr * rec / (pr + rec)\n",
    "    \n",
    "    return pr, rec, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510199\n",
      "107330\n",
      "107330\n",
      "107330\n",
      "451629\n",
      "510199\n"
     ]
    }
   ],
   "source": [
    "for item in [document_embeddings, claim_embeddings, evidence, labels, corpus_full_id, wiki_ids_experimental]:\n",
    "    print(str(len(item)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_score(document_embeddings, claim_embeddings[:2000], evidence, labels, wiki_ids_experimental, k=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, I = search_top_k(document_embeddings, claim_embeddings, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_evidence = np.take(corpus_full_id, I[0])\n",
    "print(predicted_evidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
