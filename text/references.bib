% INTRODUCTION
@book{vattimo_2013, 
    place={V Praze}, 
    title={Transparentní společnost},
    publisher={Rubato}, 
    author={Vattimo, Gianni}, 
    year={2013}
}

@book{prokop_2020, 
    place={Brno},
    title={Slepé skvrny: o chudobě, vzdělávání, populismu a dalších výzvách české společnosti}, publisher={Host}, 
    author={Prokop, Daniel}, 
    year={2020}
}

@MISC{hao_2020, 
    title={A college kid created a fake, AI-generated blog. It reached 1 on Hacker News.}, url={https://www.technologyreview.com/2020/08/14/1006780/ai-gpt-3-fake-blog-reached-top-of-hacker-news/}, 
    journal={MIT Technology Review}, 
    publisher={MIT Technology Review}, 
    author={Hao, Karen}, 
    year={2020}, 
    month={12}
}

@MISC{illing_2020, 
    title =     {"Flood the zone with shit": How misinformation overwhelmed our democracy}, 
    url =       {https://www.vox.com/policy-and-politics/2020/1/16/20991816/impeachment-trial-trump-bannon-misinformation}, 
    author =    {Illing, Sean}, 
    year =      {2020}, 
    month =     {1},
    note =    {[online; accessed 14-12-2021]},
}

% FACTCHECKING
@BOOK{fact-checking-vs-verification,
  author =  {Silverman, Craig},
  title =   {Verification and Fact Checking},
  year =    {2014},
  note =    {[online; accessed 04-09-2021]},
  url =     {https://datajournalism.com/read/handbook/verification-1}
}

@book{kovach2007elements,
  title={The Elements of Journalism: What Newspeople Should Know and the Public Should Expect},
  author={Kovach, B. and Rosenstiel, T.},
  isbn={9780307346704},
  lccn={2006023159},
  url={https://books.google.cz/books?id=iMA1WhtiRBkC},
  year={2007},
  publisher={Three Rivers Press}
}

% @MISC{demagog,
%   title =   {Demagog},
%   note =    {[online; accessed 04-09-2021]},
%   url =     {https://demagog.cz}
% }

% @MISC{politifact,
%   title =   {PolitiFact},
%   note =    {[online; accessed 04-09-2021]},
%   url =     {https://www.politifact.com/}
% }

% @MISC{factcheck.org,
%   title =   {FactCheck.org},
%   note =    {[online; accessed 04-09-2021]},
%   url =     {https://www.factcheck.org/}
% }

@inproceedings{thorne-vlachos-2018-automated,
    title = {Automated Fact Checking: Task Formulations, Methods and Future Directions},
    author = {Thorne, James and Vlachos, Andreas},
    booktitle = {Proceedings of the 27th International Conference on Computational Linguistics},
    year = {2018},
    address = {Santa Fe, New Mexico, USA},
    publisher = {Association for Computational Linguistics},
    url = {https://www.aclweb.org/anthology/C18-1283},
    pages = {3346--3359},
}

@article{thorne2018fever,
  title={FEVER: a large-scale dataset for fact extraction and verification},
  author={Thorne, James and Vlachos, Andreas and Christodoulopoulos, Christos and Mittal, Arpit},
  journal={arXiv preprint arXiv:1803.05355},
  year={2018}
}

@inproceedings{chen2017reading-drqa,
  title={Reading {Wikipedia} to Answer Open-Domain Questions},
  author={Chen, Danqi and Fisch, Adam and Weston, Jason and Bordes, Antoine},
  booktitle={Association for Computational Linguistics (ACL)},
  year={2017}
}

@article{thorne2018fact,
  title={The fact extraction and verification (fever) shared task},
  author={Thorne, James and Vlachos, Andreas and Cocarascu, Oana and Christodoulopoulos, Christos and Mittal, Arpit},
  journal={arXiv preprint arXiv:1811.10971},
  year={2018}
}

% @inproceedings{nadeem-etal-2019-fakta,
%     title = "{FAKTA}: An Automatic End-to-End Fact Checking System",
%     author = "Nadeem, Moin  and
%       Fang, Wei  and
%       Xu, Brian  and
%       Mohtarami, Mitra  and
%       Glass, James",
%     booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics (Demonstrations)",
%     month = jun,
%     year = "2019",
%     address = "Minneapolis, Minnesota",
%     publisher = "Association for Computational Linguistics",
%     url = "https://www.aclweb.org/anthology/N19-4014",
%     doi = "10.18653/v1/N19-4014",
%     pages = "78--83",
% }

@inproceedings{hanselowski-etal-2018-ukp,
    title = "{UKP}-Athene: Multi-Sentence Textual Entailment for Claim Verification",
    author = "Hanselowski, Andreas  and
      Zhang, Hao  and
      Li, Zile  and
      Sorokin, Daniil  and
      Schiller, Benjamin  and
      Schulz, Claudia  and
      Gurevych, Iryna",
    booktitle = "Proceedings of the First Workshop on Fact Extraction and {VER}ification ({FEVER})",
    month = nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W18-5516",
    doi = "10.18653/v1/W18-5516",
    pages = "103--108",
}

@inproceedings{thorne-etal-2019-fever2,
    title = "The {FEVER}2.0 Shared Task",
    author = "Thorne, James  and
      Vlachos, Andreas  and
      Cocarascu, Oana  and
      Christodoulopoulos, Christos  and
      Mittal, Arpit",
    booktitle = "Proceedings of the Second Workshop on Fact Extraction and VERification (FEVER)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D19-6601",
    doi = "10.18653/v1/D19-6601",
    pages = "1--6",
}

@inproceedings{priban-etal-2019-machine,
    title = "Machine Learning Approach to Fact-Checking in {W}est {S}lavic Languages",
    author = "P{\v{r}}ib{\'a}{\v{n}}, Pavel  and
      Hercig, Tom{\'a}{\v{s}}  and
      Steinberger, Josef",
    booktitle = "Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019)",
    month = sep,
    year = "2019",
    address = "Varna, Bulgaria",
    publisher = "INCOMA Ltd.",
    url = "https://www.aclweb.org/anthology/R19-1113",
    doi = "10.26615/978-954-452-056-4_113",
    pages = "973--979",
}


% CLASSICAL APPROACH
@Book{manning2008introduction,
 author = {Manning, Christopher},
 title = {Introduction to information retrieval},
 publisher = {Cambridge University Press},
 year = {2008},
 address = {New York},
 isbn = {978-0-511-41405-3}
 }
 
@MISC{tfidf-vs-bm25,
  author =  {Turnbull, Doug},
  title =   {BM25 The Next Generation of Lucene Relevance},
  year =    {2015},
  month =   {10},
  note =    {[online; accessed 04-02-2021]},
  url =     { https://opensourceconnections.com/blog/2015/10/16/bm25-the-next-generation-of-lucene-relevation}
}

@book{robertson2009probabilistic,
  title={The probabilistic relevance framework: BM25 and beyond},
  author={Robertson, Stephen and Zaragoza, Hugo},
  year={2009},
  publisher={Now Publishers Inc}
}

% LANGUAGE MODELS
% @misc{howard2018universal,
%     title={Universal Language Model Fine-tuning for Text Classification},
%     author={Jeremy Howard and Sebastian Ruder},
%     year={2018},
%     eprint={1801.06146},
%     archivePrefix={arXiv},
%     primaryClass={cs.CL}
% }

@misc{ruder2021lmfine-tuning,
  author = {Ruder, Sebastian},
  title = {{Recent Advances in Language Model Fine-tuning}},
  year = {2021},
  howpublished = {\url{http://ruder.io/recent-advances-lm-fine-tuning}},
}

% TREC 2020 results
@misc{trec2020overview,
    title={Overview of the TREC 2019 deep learning track},
    author={Nick Craswell and Bhaskar Mitra and Emine Yilmaz and Daniel Campos and Ellen M. Voorhees},
    year={2020},
    eprint={2003.07820},
    archivePrefix={arXiv},
    primaryClass={cs.IR}
}

@article{Lee_2019_ict,
  title={Latent Retrieval for Weakly Supervised Open Domain Question Answering},
  url={http://dx.doi.org/10.18653/v1/P19-1612},
  DOI={10.18653/v1/p19-1612},
  journal={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  publisher={Association for Computational Linguistics},
  author={Lee, Kenton and Chang, Ming-Wei and Toutanova, Kristina},
  year={2019}
}

@article{Karpukhin_2020,
  title={Dense Passage Retrieval for Open-Domain Question Answering},
  url={http://dx.doi.org/10.18653/v1/2020.emnlp-main.550},
  DOI={10.18653/v1/2020.emnlp-main.550},
  journal={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  publisher={Association for Computational Linguistics},
  author={Karpukhin, Vladimir and Oguz, Barlas and Min, Sewon and Lewis, Patrick and Wu, Ledell and Edunov, Sergey and Chen, Danqi and Yih, Wen-tau},
  year={2020}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and Rémi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = 10,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}

@MISC{alammar_transformer, 
    title =     {The Illustrated Transformer}, 
    url =       {https://jalammar.github.io/illustrated-transformer}, 
    author =    {Alammar, Jay}, 
    year =      {2018}, 
    month =     {6},
    note =    {[online; accessed 14-12-2020]},
}

@article{Rogers_2020,
  title={A Primer in BERTology: What We Know About How BERT Works},
  volume={8},
  ISSN={2307-387X},
  url={http://dx.doi.org/10.1162/tacl_a_00349},
  DOI={10.1162/tacl_a_00349},
  journal={Transactions of the Association for Computational Linguistics},
  publisher={MIT Press - Journals},
  author={Rogers, Anna and Kovaleva, Olga and Rumshisky, Anna},
  year={2020},
  pages={842–866}
}

% MULTILINGUAL MODELS
 @article{Joshi_2020,
  title={The State and Fate of Linguistic Diversity and Inclusion in the NLP World},
  url={http://dx.doi.org/10.18653/v1/2020.acl-main.560},
  DOI={10.18653/v1/2020.acl-main.560},
  journal={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  publisher={Association for Computational Linguistics},
  author={Joshi, Pratik and Santy, Sebastin and Budhiraja, Amar and Bali, Kalika and Choudhury, Monojit},
  year={2020}
}

% Cross-linguag LM
@misc{lample2019crosslingual,
    title={Cross-lingual Language Model Pretraining},
    author={Guillaume Lample and Alexis Conneau},
    year={2019},
    eprint={1901.07291},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@article{Martin_2020,
  title={CamemBERT: a Tasty French Language Model},
  url={http://dx.doi.org/10.18653/v1/2020.acl-main.645},
  DOI={10.18653/v1/2020.acl-main.645},
  journal={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  publisher={Association for Computational Linguistics},
  author={Martin, Louis and Muller, Benjamin and Ortiz Suárez, Pedro Javier and Dupont, Yoann and Romary, Laurent and de la Clergerie, Éric and Seddah, Djamé and Sagot, Benoît},
  year={2020}
}

@article{Dumitrescu_2020,
  title={The birth of Romanian BERT},
  url={http://dx.doi.org/10.18653/v1/2020.findings-emnlp.387},
  DOI={10.18653/v1/2020.findings-emnlp.387},
  journal={Findings of the Association for Computational Linguistics: EMNLP 2020},
  publisher={Association for Computational Linguistics},
  author={Dumitrescu, Stefan and Avram, Andrei-Marius and Pyysalo, Sampo},
  year={2020}
}

% XLM-R
@article{Conneau_2020,
  title={Unsupervised Cross-lingual Representation Learning at Scale},
  url={http://dx.doi.org/10.18653/v1/2020.acl-main.747},
  DOI={10.18653/v1/2020.acl-main.747},
  journal={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  publisher={Association for Computational Linguistics},
  author={Conneau, Alexis and Khandelwal, Kartikay and Goyal, Naman and Chaudhary, Vishrav and Wenzek, Guillaume and Guzmán, Francisco and Grave, Edouard and Ott, Myle and Zettlemoyer, Luke and Stoyanov, Veselin},
  year={2020}
}

@misc{li2021scaling,
    title={Scaling End-to-End Models for Large-Scale Multilingual ASR},
    author={Bo Li and Ruoming Pang and Tara N. Sainath and Anmol Gulati and Yu Zhang and James Qin and Parisa Haghani and W. Ronny Huang and Min Ma},
    year={2021},
    eprint={2104.14830},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@article{Mackov_2020_czech_xlmr,
  title={Reading Comprehension in Czech via Machine Translation and Cross-Lingual Transfer},
  ISBN={9783030583231},
  ISSN={1611-3349},
  url={http://dx.doi.org/10.1007/978-3-030-58323-1_18},
  DOI={10.1007/978-3-030-58323-1_18},
  journal={Lecture Notes in Computer Science},
  publisher={Springer International Publishing},
  author={Macková, Kateřina and Straka, Milan},
  year={2020},
  pages={171–179}
}

@misc{sido2021czert,
    title={Czert -- Czech BERT-like Model for Language Representation},
    author={Jakub Sido and Ondřej Pražák and Pavel Přibáň and Jan Pašek and Michal Seják and Miloslav Konopík},
    year={2021},
    eprint={2103.13031},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

% How Cross-lingual is BERT
% @article{Pires_2019,
%   title={How Multilingual is Multilingual BERT?},
%   url={http://dx.doi.org/10.18653/v1/P19-1493},
%   DOI={10.18653/v1/p19-1493},
%   journal={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
%   publisher={Association for Computational Linguistics},
%   author={Pires, Telmo and Schlinger, Eva and Garrette, Dan},
%   year={2019}
% }

% Cross-lingual BERT
% @misc{crosslingual-mbert,
%     title={Cross-Lingual Ability of Multilingual BERT: An Empirical Study},
%     author={Karthikeyan K and Zihan Wang and Stephen Mayhew and Dan Roth},
%     year={2019},
%     eprint={1912.07840},
%     archivePrefix={arXiv},
%     primaryClass={cs.CL}
% }


% DISTILLATION
@misc{shoeybi2019megatronlm,
    title={Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism},
    author={Mohammad Shoeybi and Mostofa Patwary and Raul Puri and Patrick LeGresley and Jared Casper and Bryan Catanzaro},
    year={2019},
    eprint={1909.08053},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{brown2020language-gpt3,
    title={Language Models are Few-Shot Learners},
    author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
    year={2020},
    eprint={2005.14165},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@article{Schwartz_2020,
  title={Green AI},
  volume={63},
  ISSN={1557-7317},
  url={http://dx.doi.org/10.1145/3381831},
  DOI={10.1145/3381831},
  number={12},
  journal={Communications of the ACM},
  publisher={Association for Computing Machinery (ACM)},
  author={Schwartz, Roy and Dodge, Jesse and Smith, Noah A. and Etzioni, Oren},
  year={2020},
  month={11},
  pages={54–63}
}

@MISC{language-models-comparison, 
    title={Turing-NLG: A 17-billion-parameter language model by Microsoft}, url={https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/}, 
    publisher={Microsoft}, 
    author={Rosset, Corby}, 
    year={2020}, 
    month={2}
}

@article{Sanh2019DistilBERTAD,
  title={DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter},
  author={Victor Sanh and Lysandre Debut and Julien Chaumond and Thomas Wolf},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.01108}
}

@inproceedings{distillation,
    author = {Buciluundefined, Cristian and Caruana, Rich and Niculescu-Mizil, Alexandru},
    title = {Model Compression},
    year = {2006},
    isbn = {1595933395},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/1150402.1150464},
    doi = {10.1145/1150402.1150464},
    booktitle = {Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
    pages = {535–541},
    numpages = {7},
    keywords = {model compression, supervised learning},
    location = {Philadelphia, PA, USA},
    series = {KDD '06}
}

@misc{hinton2015distilling,
    title={Distilling the Knowledge in a Neural Network},
    author={Geoffrey Hinton and Oriol Vinyals and Jeff Dean},
    year={2015},
    eprint={1503.02531},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}

@misc{hofstaetter2020_crossarchitecture_kd,
      title={Improving Efficient Neural Ranking Models with Cross-Architecture Knowledge Distillation}, 
      author={Sebastian Hofst{\"a}tter and Sophia Althammer and Michael Schr{\"o}der and Mete Sertkan and Allan Hanbury},
      year={2020},
      eprint={2010.02666},
      archivePrefix={arXiv},
      primaryClass={cs.IR}
}

@article{Reimers_2020-distillation-multiling,
  title={Making Monolingual Sentence Embeddings Multilingual using Knowledge Distillation},
  url={http://dx.doi.org/10.18653/v1/2020.emnlp-main.365},
  DOI={10.18653/v1/2020.emnlp-main.365},
  journal={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  publisher={Association for Computational Linguistics},
  author={Reimers, Nils and Gurevych, Iryna},
  year={2020}
}


% TOKENIZATION
@misc{tokenizers-huggingface, 
    title={Summary of the tokenizers}, url={https://huggingface.co/transformers/tokenizer_summary.html}, 
    journal={Summary of the tokenizers - transformers 4.3.0 documentation}
}

@INPROCEEDINGS{wordpiece-tokenizer,
  author={M. {Schuster} and K. {Nakajima}},
  booktitle={2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Japanese and Korean voice search}, 
  year={2012},
  volume={},
  number={},
  pages={5149-5152},
  doi={10.1109/ICASSP.2012.6289079}}

@article{BPE-tokenizer,
  title={Neural Machine Translation of Rare Words with Subword Units},
  url={http://dx.doi.org/10.18653/v1/P16-1162},
  DOI={10.18653/v1/p16-1162},
  journal={Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  publisher={Association for Computational Linguistics},
  author={Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  year={2016}
}

@article{sentencepiece-tokenizer,
  title={SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing},
  url={http://dx.doi.org/10.18653/v1/D18-2012},
  DOI={10.18653/v1/d18-2012},
  journal={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
  publisher={Association for Computational Linguistics},
  author={Kudo, Taku and Richardson, John},
  year={2018}
} 

@article{unigram-toknizer,
  title={Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates},
  url={http://dx.doi.org/10.18653/v1/P18-1007},
  DOI={10.18653/v1/p18-1007},
  journal={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  publisher={Association for Computational Linguistics},
  author={Kudo, Taku},
  year={2018}
}

%HYBRID APPROACH
@misc{nogueira2019passage,
    title={Passage Re-ranking with BERT},
    author={Rodrigo Nogueira and Kyunghyun Cho},
    year={2019},
    eprint={1901.04085},
    archivePrefix={arXiv},
    primaryClass={cs.IR}
}

%Bertserini
@article{bertserini,
  title={End-to-End Open-Domain Question Answering with Bertserini},
  url={http://dx.doi.org/10.18653/v1/N19-4013},
  DOI={10.18653/v1/n19-4013},
  journal={Proceedings of the 2019 Conference of the North},
  publisher={Association for Computational Linguistics},
  author={Yang, Wei and Xie, Yuqing and Lin, Aileen and Li, Xingyu and Tan, Luchen and Xiong, Kun and Li, Ming and Lin, Jimmy},
  year={2019}
}

%Birch
@inproceedings{birch,
  title={Applying BERT to document retrieval with birch},
  author={Yilmaz, Zeynep Akkalyoncu and Wang, Shengjin and Yang, Wei and Zhang, Haotian and Lin, Jimmy},
  booktitle={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations},
  pages={19--24},
  year={2019}
}

@misc{diggelmann2020climatefever,
    title={CLIMATE-FEVER: A Dataset for Verification of Real-World Climate Claims},
    author={Thomas Diggelmann and Jordan Boyd-Graber and Jannis Bulian and Massimiliano Ciaramita and Markus Leippold},
    year={2020},
    eprint={2012.00614},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

% @MISC{ms-marco-results,
%   title =   {MS MARCO},
%   note =    {[online; accessed 04-15-2021]},
%   url =     {https://microsoft.github.io/msmarco/}
% }

@misc{nogueira2019document,
    title={Document Expansion by Query Prediction},
    author={Rodrigo Nogueira and Wei Yang and Jimmy Lin and Kyunghyun Cho},
    year={2019},
    eprint={1904.08375},
    archivePrefix={arXiv},
    primaryClass={cs.IR}
}

@article{nogueira2019doc2query,
  title={From doc2query to docTTTTTquery},
  author={Nogueira, Rodrigo and Lin, Jimmy and Epistemic, AI},
  year={2019}
}

@misc{dai2019contextaware,
    title={Context-Aware Sentence/Passage Term Importance Estimation For First Stage Retrieval},
    author={Zhuyun Dai and Jamie Callan},
    year={2019},
    eprint={1910.10687},
    archivePrefix={arXiv},
    primaryClass={cs.IR}
}


% CROSS ATTENTION
@misc{mitra-intro-to-ir,
    title={An introduction to neural information retrieval},
    author={Mitra Bhaskar, Craswell Nick, et al.},
    year={2018},
}


%TWO TOWER
@article{chang2020twotower,
  title={Pre-training tasks for embedding-based large-scale retrieval},
  author={Chang, Wei-Cheng and Yu, Felix X and Chang, Yin-Wen and Yang, Yiming and Kumar, Sanjiv},
  journal={arXiv preprint arXiv:2002.03932},
  year={2020}
}

@misc{cer2018universal,
    title={Universal Sentence Encoder},
    author={Daniel Cer and Yinfei Yang and Sheng-yi Kong and Nan Hua and Nicole Limtiaco and Rhomni St. John and Noah Constant and Mario Guajardo-Cespedes and Steve Yuan and Chris Tar and Yun-Hsuan Sung and Brian Strope and Ray Kurzweil},
    year={2018},
    eprint={1803.11175},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@article{Reimers_2019-SBERT,
  title={Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks},
  url={http://dx.doi.org/10.18653/v1/D19-1410},
  DOI={10.18653/v1/d19-1410},
  journal={Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
  publisher={Association for Computational Linguistics},
  author={Reimers, Nils and Gurevych, Iryna},
  year={2019}
}

@misc{lu2020twinbert,
    title={TwinBERT: Distilling Knowledge to Twin-Structured BERT Models for Efficient Retrieval},
    author={Wenhao Lu and Jian Jiao and Ruofei Zhang},
    year={2020},
    eprint={2002.06275},
    archivePrefix={arXiv},
    primaryClass={cs.IR}
}

@inproceedings{ein-dor-etal-2018-learning,
    title = "Learning Thematic Similarity Metric from Article Sections Using Triplet Networks",
    author = "Ein Dor, Liat  and
      Mass, Yosi  and
      Halfon, Alon  and
      Venezian, Elad  and
      Shnayderman, Ilya  and
      Aharonov, Ranit  and
      Slonim, Noam",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P18-2009",
    doi = "10.18653/v1/P18-2009",
    pages = "49--54",
}

@misc{ding2020rocketqa,
    title={RocketQA: An Optimized Training Approach to Dense Passage Retrieval for Open-Domain Question Answering},
    author={Yingqi Qu Yuchen Ding and Jing Liu and Kai Liu and Ruiyang Ren and Xin Zhao and Daxiang Dong and Hua Wu and Haifeng Wang},
    year={2020},
    eprint={2010.08191},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}


%% COLBERT
@article{colbert_2020,
  title={ColBERT},
  ISBN={9781450380164},
  url={http://dx.doi.org/10.1145/3397271.3401075},
  DOI={10.1145/3397271.3401075},
  journal={Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
  publisher={ACM},
  author={Khattab, Omar and Zaharia, Matei},
  year={2020},
  month={7},
  note={Implementation: \url{https://github.com/stanford-futuredata/ColBERT}}
}

@article{Johnson_2019_faiss,
  title={Billion-scale similarity search with GPUs},
  ISSN={2372-2096},
  url={http://dx.doi.org/10.1109/tbdata.2019.2921572},
  DOI={10.1109/tbdata.2019.2921572},
  journal={IEEE Transactions on Big Data},
  publisher={Institute of Electrical and Electronics Engineers (IEEE)},
  author={Johnson, Jeff and Douze, Matthijs and Jegou, Herve},
  year={2019},
  pages={1–1}
}


% LONGFORMER APPROACHES
@misc{beltagy2020longformer,
    title={Longformer: The Long-Document Transformer},
    author={Iz Beltagy and Matthew E. Peters and Arman Cohan},
    year={2020},
    eprint={2004.05150},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{wang2020linformer,
    title={Linformer: Self-Attention with Linear Complexity},
    author={Sinong Wang and Belinda Z. Li and Madian Khabsa and Han Fang and Hao Ma},
    year={2020},
    eprint={2006.04768},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{Roy_2021,
  title={Efficient Content-Based Sparse Attention with Routing Transformers},
  volume={9},
  ISSN={2307-387X},
  url={http://dx.doi.org/10.1162/tacl_a_00353},
  DOI={10.1162/tacl_a_00353},
  journal={Transactions of the Association for Computational Linguistics},
  publisher={MIT Press - Journals},
  author={Roy, Aurko and Saffar, Mohammad and Vaswani, Ashish and Grangier, David},
  year={2021},
  month={2},
  pages={53–68}
}

@MISC{long_survey_2020, 
    title =     {A Survey of Long-Term Context in Transformers}, 
    url =       {https://www.pragmatic.ml/a-survey-of-methods-for-incorporating-long-term-context}, 
    author =    {Madison, May}, 
    year =      {2020}, 
    note =    {[online; accessed 15-04-2021]},
}

% Longformer 1
% @article{hoffstater-long-1,
%   title={Local Self-Attention over Long Text for Efficient Document Retrieval},
%   ISBN={9781450380164},
%   url={http://dx.doi.org/10.1145/3397271.3401224},
%   DOI={10.1145/3397271.3401224},
%   journal={Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
%   publisher={ACM},
%   author={Hofstätter, Sebastian and Zamani, Hamed and Mitra, Bhaskar and Craswell, Nick and Hanbury, Allan},
%   year={2020},
%   month={7}
% }


% DATASETS
% CLAIM QUALITY
@article{binau2020danish,
  title={Danish Fact Verification: An End-to-End Machine Learning System for Automatic Fact-Checking of Danish Textual Claims},
  author={Binau, Julie and Schulte, Henri},
  year={2020}
}


% @misc{wikimedia-dump,
%   title = {Wikimedia Dumps},
%   howpublished = {\url{https://dumps.wikimedia.org/}},
% }

@misc{wikiextractor,
  author = {Attardi, Giuseppe},
  title = {WikiExtractor},
  year = {2019},
  publisher = {Wikimedia},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/attardi/wikiextractor}},
  comment = {version 0.1}
}

% @misc{fever-web,
%   title = {FEVER Website},
%   year = {2018},
%   howpublished = {\url{https://fever.ai/resources.html}},
% }


@mastersthesis{herbert-mt,
    author = {Ullrich, Herbert},
    title = {Dataset for Automated Fact Checking in Czech Language},
    school = {Czech Technical University in Prague},
    year = {2021},
    note = {\url{https://www.overleaf.com/read/nfxjywqwthgx}}
}

@mastersthesis{bara-mt,
    title={Multi-stage Methods for Document Retrieval in the Czech Language},
    author={Dědková, Barbora},
    school = {Czech Technical University in Prague},
    year = {2021},
    note = {\url{https://www.overleaf.com/read/gkymfyhfkrkq}}
}

@mastersthesis{alex-mt,
    title={Algorithms for Document Retrieval in Czech Language Supporting Long Inputs},
    author={Gažo, Alexander},
    school = {Czech Technical University in Prague},
    year = {2021},
    note = {\url{https://gitlab.fel.cvut.cz/gazoalex/master-thesis/-/tree/master}}
}

% @misc{michal,
%   author={Michal Pitr},
%   title = "\textsf{CTU FEE GitLab} -- {Experimental}: Michal~{Pitr}",
%   year = "2020",
%   howpublished = {\url{https://gitlab.fel.cvut.cz/factchecking/experimental-michal_pitr}},
%   note = "[Online; accessed 14-May-2021]"
% }

% @misc{grant,
%   title = {Transformation of Journalisms Ethics in the Advent of Artificial Intelligence},
%   year = {2019},
%   publisher = {TAČR},
%   howpublished = {\url{https://starfos.tacr.cz/cs/project/TL02000288?query_code=6uxyaab7klva}},
% }


@inproceedings{derczynski-etal-2020-claim-quality,
    title = "Maintaining Quality in {FEVER} Annotation",
    author = "Derczynski, Leon  and
      Binau, Julie  and
      Schulte, Henri",
    booktitle = "Proceedings of the Third Workshop on Fact Extraction and VERification (FEVER)",
    month = 7,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.fever-1.6",
    doi = "10.18653/v1/2020.fever-1.6",
    pages = "42--46",
}

@article{Niven_2019,
  title={Probing Neural Network Comprehension of Natural Language Arguments},
  url={http://dx.doi.org/10.18653/v1/P19-1459},
  DOI={10.18653/v1/p19-1459},
  journal={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  publisher={Association for Computational Linguistics},
  author={Niven, Timothy and Kao, Hung-Yu},
  year={2019}
}

% PROPOSED SOLUTION
% BASELINE
@article{Yang_2019,
  title={Critically Examining the “Neural Hype”},
  ISBN={9781450361729},
  url={http://dx.doi.org/10.1145/3331184.3331340},
  DOI={10.1145/3331184.3331340},
  journal={Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
  publisher={ACM},
  author={Yang, Wei and Lu, Kuang and Yang, Peilin and Lin, Jimmy},
  year={2019},
  month={7}
}

@misc{lin2021pyserini,
    title={Pyserini: An Easy-to-Use Python Toolkit to Support Replicable IR Research with Sparse and Dense Representations},
    author={Jimmy Lin and Xueguang Ma and Sheng-Chieh Lin and Jheng-Hong Yang and Ronak Pradeep and Rodrigo Nogueira},
    year={2021},
    eprint={2102.10073},
    archivePrefix={arXiv},
    primaryClass={cs.IR},
    url={https://github.com/castorini/anserini}
}

% @misc{colbert-github,
%   author = {Khattab, Omar and Zaharia, Matei},
%   title = {ColBERT},
%   year = {2020},
%   publisher = {Stanford University},
%   journal = {GitHub repository},
%   howpublished = {\url{https://github.com/stanford-futuredata/ColBERT}},
%   comment = {v0.2.0}
% }

% @misc{n2021beir,
%     title={BEIR: A Heterogenous Benchmark for Zero-shot Evaluation of Information Retrieval Models},
%     author={Nandan Thakur and Nils Reimers and Andreas Rücklé and Abhishek Srivastava and Iryna Gurevych},
%     year={2021},
%     eprint={2104.08663},
%     archivePrefix={arXiv},
%     primaryClass={cs.IR}
% }

% EXPERIMENTAL
% CONCLUSION
% @misc{reimers2020curse-lowdim,
%     title={The Curse of Dense Low-Dimensional Information Retrieval for Large Index Sizes},
%     author={Nils Reimers and Iryna Gurevych},
%     year={2020},
%     eprint={2012.14210},
%     archivePrefix={arXiv},
%     primaryClass={cs.IR}
% }